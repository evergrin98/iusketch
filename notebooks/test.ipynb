{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import apps.config_env as cfg\n",
    "\n",
    "from classes.image_frame import ImgFrame\n",
    "from classes.video_clip import VideoClip\n",
    "from models.dataset_generator import DataSetGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from models.layer_conv import Conv2Plus1D, TConv2Plus1D\n",
    "# from models.layer_encoder import Encoder5D, Decoder5D\n",
    "# from models.layer_lstm import ConvLstmSeries\n",
    "\n",
    "img_w, img_h = 64, 64 #cfg.DATA_IMG_W, cfg.DATA_IMG_H\n",
    "batch_size = 2 #cfg.DATA_BATCH_SIZE\n",
    "time_steps = 8 # cfg.DATA_TIME_STEP\n",
    "enc_blk_count = 5  # 3 - 7\n",
    "disc_blk_count = 3 # \n",
    "EPOCHS = 50\n",
    "\n",
    "enc_filters = [64,128,256,512,512,512,512,512]\n",
    "dec_filters = [512,512,512,512,256,128,64]\n",
    "\n",
    "\n",
    "# dataset 설정.\n",
    "data_seq_type = 'aforward'  # 'all', 'rest', 'arandom', 'aforward', 'forward', 'reverse', 'random'\n",
    "data_label_type = 'same'   # 'all', 'rest', 'same', '1step'\n",
    "stakced = False\n",
    "overlap = False\n",
    "\n",
    "# 전체 raw_clip 랜덤한 이미지 목록을 가져옴.\n",
    "img_list = glob.glob(os.path.join(cfg.RAW_CLIP_PATH, \"*.gif\"))\n",
    "random.shuffle(img_list)\n",
    "\n",
    "# 이미지 목록을 train/validation용으로 9:1로 나눔.\n",
    "train_val_ratio = 0.9\n",
    "train_img_cnt = int(len(img_list) * train_val_ratio)\n",
    "train_img_list = img_list[:train_img_cnt]\n",
    "val_img_list = img_list[train_img_cnt:]\n",
    "\n",
    "# train/validation용 generator를 생성.\n",
    "tdgen = DataSetGenerator(imgs=train_img_list, batch_size=batch_size, \n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "                         seq_type=data_seq_type, label_type=data_label_type,\n",
    "                         stacked=stakced, overlap=overlap)\n",
    "\n",
    "vdgen = DataSetGenerator(imgs=val_img_list, batch_size=batch_size, \n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "                         seq_type=data_seq_type, label_type=data_label_type,\n",
    "                         stacked=stakced, overlap=overlap)\n",
    "\n",
    "def arry5d_to_img(arry5d, save_as='', threshold=0.0):\n",
    "    frmimg_cnt = arry5d.shape[1]\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = frmimg_cnt, figsize=(15, 3))\n",
    "\n",
    "    for idx, num in enumerate(range(0, frmimg_cnt)):\n",
    "        frm = ImgFrame(img=arry5d[0][idx][:, :, :], do_norm=False)\n",
    "        min_val = np.min(frm.arry)\n",
    "        max_val = np.max(frm.arry)\n",
    "        frm.arry = (frm.arry - min_val) / (max_val - min_val)\n",
    "\n",
    "        min_val = np.min(frm.arry)\n",
    "        max_val = np.max(frm.arry)\n",
    "        # print(\"min,max: \", np.min(frm.arry), np.max(frm.arry))\n",
    "\n",
    "        if threshold > 0.0:\n",
    "            frm.threshold(threshold=threshold)\n",
    "\n",
    "        img = frm.to_image()\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def show_imgs(arry1, arry2):\n",
    "    frmimg_cnt = arry1.shape[1]\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = frmimg_cnt, figsize=(15, 3))\n",
    "    arrys = [arry1, arry2]\n",
    "    \n",
    "    for i, arry in enumerate(arrys):\n",
    "        for idx, num in enumerate(range(0, frmimg_cnt)):\n",
    "            frm = ImgFrame(img=arry[0][idx][:, :, :], do_norm=False)\n",
    "            min_val = np.min(frm.arry)\n",
    "            max_val = np.max(frm.arry)\n",
    "            frm.arry = (frm.arry - min_val) / (max_val - min_val)\n",
    "\n",
    "            min_val = np.min(frm.arry)\n",
    "            max_val = np.max(frm.arry)\n",
    "            # print(\"min,max: \", np.min(frm.arry), np.max(frm.arry))\n",
    "\n",
    "            img = frm.to_image()\n",
    "            axes[i][idx].imshow(img, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset중 하나만 뽑아서 예측에 입력\n",
    "it = iter(vdgen)\n",
    "x, y = next(it)\n",
    "\n",
    "clip = VideoClip()\n",
    "clip.from_array(y[0, :, :, :, :], do_norm=False)\n",
    "clip = clip.stacked_frames_clip()\n",
    "arry = clip.to_array(expand=True)\n",
    "\n",
    "# x 이미지 한개 표시\n",
    "arry5d_to_img(arry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.frame_maker import FrameMaker\n",
    "\n",
    "dlg = FrameMaker()\n",
    "dlg.runModal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils.files import dir_path_change\n",
    "from classes.image_frame import ImgFrame\n",
    "from classes.video_clip import VideoClip\n",
    "\n",
    "IMG_LOAD_BASE_PATH = '/home/evergrin/iu/datas/imgs/raw_imgs/raw_gif/raw_gif_512_100/'\n",
    "IMG_SAVE_BASE_PATH = '/home/evergrin/iu/datas/imgs/raw_imgs/raw_gif/resize_gif/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디렉토리에 있는 gif file을 1/2 사이즈로 일괄 변경한다.\n",
    "\n",
    "gif_list = glob.glob(os.path.join(IMG_LOAD_BASE_PATH, \"*.gif\"))\n",
    "\n",
    "for gif_file in gif_list:\n",
    "\n",
    "    vclip = VideoClip()\n",
    "    vclip.load_gif(gif_file, grayscale=True)\n",
    "    new_file = dir_path_change(gif_file, IMG_SAVE_BASE_PATH, \"gif\")\n",
    "    vclip.make_gif(new_file, ratio=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리에 있는 gif file을 1/2 사이즈로 일괄 변경한다.\n",
    "\n",
    "gif_list = glob.glob(os.path.join(IMG_LOAD_BASE_PATH, \"*.gif\"))\n",
    "\n",
    "for idx, gif_file in enumerate(gif_list):\n",
    "\n",
    "    clip = VideoClip(gif_path=gif_file)\n",
    "    \n",
    "    imgfrm = ImgFrame(img=clip.clips[0], do_norm=False)\n",
    "    \n",
    "    # vclip.load_gif(gif_file, grayscale=True)\n",
    "    file_name = os.path.join(IMG_SAVE_BASE_PATH, f\"lion_{500+idx:04d}.png\")\n",
    "    imgfrm.to_image(save_file=file_name)\n",
    "    # new_file = dir_path_change(gif_file, IMG_SAVE_BASE_PATH, \"gif\")\n",
    "    # vclip.make_gif(new_file, ratio=0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv_3912')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6debceb626036820d184549e25d059a55b6b8771e25bc8133db281d329c34fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
