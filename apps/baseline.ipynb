{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IU Sketch Baseline 코드  \n",
    " - python모듈 설치 코드는 처음 한번 실행해주세요.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imageio\n",
    "# !pip install imageio --upgrade\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 path 설정.\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이스 라인 코드.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "\n",
    "\n",
    "import config_env as cfg\n",
    "\n",
    "from classes.image_frame import ImgFrame\n",
    "from classes.video_clip import VideoClip\n",
    "from models.dataset_generator import DataSetGenerator\n",
    "from models.layer_conv import Conv2Plus1D, TConv2Plus1D\n",
    "from models.layer_encoder import Encoder5D, Decoder5D\n",
    "from models.layer_lstm import ConvLstmSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 디렉토리 없으면 생성.\n",
    "\n",
    "# 학습용 raw_clip(gif) 파일 위치.\n",
    "if not os.path.exists(cfg.RAW_CLIP_PATH):\n",
    "    os.mkdir(cfg.RAW_CLIP_PATH)\n",
    "\n",
    "# 모델 저장 위치\n",
    "if not os.path.exists(cfg.MODEL_SAVE_PATH):\n",
    "    os.mkdir(cfg.MODEL_SAVE_PATH)\n",
    "\n",
    "# 임시 데이터 저장 위치\n",
    "if not os.path.exists(cfg.TEMP_DATA_PATH):\n",
    "    os.mkdir(cfg.TEMP_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 128, 128 #cfg.DATA_IMG_W, cfg.DATA_IMG_H\n",
    "batch_size = 4 #cfg.DATA_BATCH_SIZE\n",
    "time_steps = cfg.DATA_TIME_STEP\n",
    "\n",
    "# encoder-decoder 모델 사용시\n",
    "is_autoenc_model = False\n",
    "\n",
    "# 전체 raw_clip 랜덤한 이미지 목록을 가져옴.\n",
    "img_list = glob.glob(os.path.join(cfg.RAW_CLIP_PATH, \"*.gif\"))\n",
    "random.shuffle(img_list)\n",
    "\n",
    "# 이미지 목록을 train/validation용으로 9:1로 나눔.\n",
    "train_val_ratio = 0.9\n",
    "train_img_cnt = int(len(img_list) * train_val_ratio)\n",
    "train_img_list = img_list[:train_img_cnt]\n",
    "val_img_list = img_list[train_img_cnt:]\n",
    "\n",
    "# train/validation용 generator를 생성.\n",
    "tdgen = DataSetGenerator(imgs=train_img_list, batch_size=batch_size, time_step=time_steps, imgw=img_w, imgh=img_h, is_train=False, for_enc=is_autoenc_model)\n",
    "vdgen = DataSetGenerator(imgs=val_img_list, batch_size=batch_size, time_step=time_steps, imgw=img_w, imgh=img_h, is_train=False, for_enc=is_autoenc_model)\n",
    "\n",
    "\n",
    "# encoder - lstms - decoder - retina(0) 모델을 생성.\n",
    "enc_in_filters = 128\n",
    "enc_conv_count = 3\n",
    "lstm_count = 3\n",
    "dec_conv_count = 3\n",
    "retina_conv_count = 3\n",
    "\n",
    "enc_out_filters = enc_in_filters*2**(enc_conv_count-1)\n",
    "dec_in_filters = enc_out_filters // 2\n",
    "retina_in_filters = dec_in_filters // 2**(dec_conv_count)\n",
    "\n",
    "encoder = Encoder5D(enc_conv_count, enc_in_filters, (1, 3, 3), 2, \"same\")\n",
    "decoder = Decoder5D(dec_conv_count, dec_in_filters, (1, 3, 3), 2, \"same\")\n",
    "lstms = ConvLstmSeries(enc_out_filters, 0, [(3, 3), (3, 3), (3, 3)])\n",
    "retina = Encoder5D(retina_conv_count, retina_in_filters, (1, 3, 3), 1, \"same\", out_channel=1)\n",
    "retina0 = Encoder5D(0, retina_in_filters, (1, 3, 3), 1, \"same\", out_channel=1)\n",
    "# threshold_relu = ThresholdedReLU(theta=0.5)\n",
    "\n",
    "inputs = layers.Input(shape=(None, img_w, img_h, 1))\n",
    "\n",
    "if is_autoenc_model:\n",
    "    x = encoder(inputs)\n",
    "    x = decoder(x)\n",
    "    x = retina0(x)\n",
    "\n",
    "else:\n",
    "    x = encoder(inputs)\n",
    "    x = lstms(x)\n",
    "    x = decoder(x)\n",
    "    x = retina(x)\n",
    "\n",
    "# x = threshold_relu(x)\n",
    "outputs = x\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name='sketcher')\n",
    "model.compile(optimizer = keras.optimizers.Adam(1e-4), loss = 'binary_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, show_shapes=True, expand_nested=False, show_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(encoder.seq, show_shapes=True, expand_nested=True, show_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(lstms.seq, show_shapes=True, expand_nested=True, show_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(decoder.seq, show_shapes=True, expand_nested=True, show_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(retina.seq, show_shapes=True, expand_nested=True, show_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all(prefix='base_200'):\n",
    "    model.save(os.path.join(cfg.MODEL_SAVE_PATH, f\"sketcher_{prefix}\"))\n",
    "    encoder.seq.save(os.path.join(cfg.MODEL_SAVE_PATH, f\"enc_{prefix}\"))\n",
    "    lstms.seq.save(os.path.join(cfg.MODEL_SAVE_PATH, f\"lstm_{prefix}\"))\n",
    "    decoder.seq.save(os.path.join(cfg.MODEL_SAVE_PATH, f\"dec_{prefix}\"))\n",
    "    retina.seq.save(os.path.join(cfg.MODEL_SAVE_PATH, f\"retina_{prefix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(prefix='base_200'):\n",
    "    encoder.seq = keras.models.load_model(os.path.join(cfg.MODEL_SAVE_PATH, f\"enc_{prefix}\"))\n",
    "    lstms.seq = keras.models.load_model(os.path.join(cfg.MODEL_SAVE_PATH, f\"lstm_{prefix}\"))\n",
    "    decoder.seq = keras.models.load_model(os.path.join(cfg.MODEL_SAVE_PATH, f\"dec_{prefix}\"))\n",
    "    retina.seq = keras.models.load_model(os.path.join(cfg.MODEL_SAVE_PATH, f\"retina_{prefix}\"))\n",
    "#     model = keras.models.load_model(os.path.join(cfg.MODEL_SAVE_PATH, f\"sketcher_{prefix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_all(prefix='base_300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.trainable = False\n",
    "# decoder.trainable = False\n",
    "# lstms.trainable = False\n",
    "# retina.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_cnt = 400\n",
    "steps_per_epoch = 50\n",
    "val_steps = 2\n",
    "\n",
    "history = model.fit(\n",
    "            tdgen,\n",
    "            validation_data = vdgen,\n",
    "            steps_per_epoch = steps_per_epoch,\n",
    "            validation_steps = val_steps,\n",
    "            epochs = epoch_cnt,\n",
    "            batch_size = batch_size,\n",
    "            verbose = 1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all(prefix='base_400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arry5d_to_img(arry5d, save_as=''):\n",
    "    frm = ImgFrame(img=arry5d[0][-1][:, :, :], do_norm=False)\n",
    "\n",
    "    # 예측 결과 표시.\n",
    "    # frm.arry = frm.arry * 255\n",
    "    img = frm.to_image(save_file=save_as)\n",
    "    plt.imshow(img, cmap='gray')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset중 하나만 뽑아서 예측에 입력\n",
    "it = iter(vdgen)\n",
    "x, y = next(it)\n",
    "in_x = x[:1, :, :, :, :]\n",
    "print(x.shape, y.shape, in_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 이미지 한개 표시\n",
    "arry5d_to_img(in_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 이미지 한개 표시.\n",
    "arry5d_to_img(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 예측하여 이미지 표시.\n",
    "pred = model.predict(in_x)\n",
    "\n",
    "file_name = os.path.join(cfg.TEMP_DATA_PATH, 'result.gif')\n",
    "arry5d_to_img(pred, save_as=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user가 그린 임의의 그림 예측.\n",
    "user_file_name = os.path.join(cfg.TEMP_DATA_PATH, 'user_draw.gif')\n",
    "user_draw = VideoClip(gif_path=user_file_name)\n",
    "user_draw.resize(128, 128, inplace=True)\n",
    "arry5d = user_draw.to_array(expand=True)\n",
    "print(arry5d.shape)\n",
    "\n",
    "pred = model.predict(arry5d)\n",
    "\n",
    "file_name = os.path.join(cfg.TEMP_DATA_PATH, 'result.gif')\n",
    "arry5d_to_img(pred, save_as=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6debceb626036820d184549e25d059a55b6b8771e25bc8133db281d329c34fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
