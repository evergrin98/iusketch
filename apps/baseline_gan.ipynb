{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IU Sketch Baseline 코드  \n",
    " - python모듈 설치 코드는 처음 한번 실행해주세요.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imageio\n",
    "# !pip install imageio --upgrade\n",
    "# !pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 path 설정.\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이스 라인 코드.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import config_env as cfg\n",
    "\n",
    "from classes.image_frame import ImgFrame\n",
    "from classes.video_clip import VideoClip\n",
    "from models.dataset_generator import DataSetGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from models.layer_conv import Conv2Plus1D, TConv2Plus1D\n",
    "# from models.layer_encoder import Encoder5D, Decoder5D\n",
    "# from models.layer_lstm import ConvLstmSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 디렉토리 없으면 생성.\n",
    "\n",
    "# 학습용 raw_clip(gif) 파일 위치.\n",
    "if not os.path.exists(cfg.RAW_CLIP_PATH):\n",
    "    os.mkdir(cfg.RAW_CLIP_PATH)\n",
    "\n",
    "# 모델 저장 위치\n",
    "if not os.path.exists(cfg.MODEL_SAVE_PATH):\n",
    "    os.mkdir(cfg.MODEL_SAVE_PATH)\n",
    "\n",
    "# 임시 데이터 저장 위치\n",
    "if not os.path.exists(cfg.TEMP_DATA_PATH):\n",
    "    os.mkdir(cfg.TEMP_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 64, 64 #cfg.DATA_IMG_W, cfg.DATA_IMG_H\n",
    "batch_size = 4 #cfg.DATA_BATCH_SIZE\n",
    "time_steps = 8 # cfg.DATA_TIME_STEP\n",
    "enc_blk_count = 6  # 3 - 7\n",
    "disc_blk_count = 3 # \n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "# dataset 설정.\n",
    "data_seq_type = 'all'  # 'all', 'rest', 'arandom', 'aforward', 'forward', 'reverse', 'random'\n",
    "data_label_type = '1step'   # 'all', 'rest', 'same', '1step'\n",
    "stakced = False\n",
    "overlap = False\n",
    "\n",
    "# 전체 raw_clip 랜덤한 이미지 목록을 가져옴.\n",
    "img_list = glob.glob(os.path.join(cfg.RAW_CLIP_PATH, \"*.gif\"))\n",
    "random.shuffle(img_list)\n",
    "\n",
    "# 이미지 목록을 train/validation용으로 9:1로 나눔.\n",
    "train_val_ratio = 0.9\n",
    "train_img_cnt = int(len(img_list) * train_val_ratio)\n",
    "train_img_list = img_list[:train_img_cnt]\n",
    "val_img_list = img_list[train_img_cnt:]\n",
    "\n",
    "# train/validation용 generator를 생성.\n",
    "tdgen = DataSetGenerator(imgs=train_img_list, batch_size=batch_size, \n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "                         seq_type=data_seq_type, label_type=data_label_type,\n",
    "                         stacked=stakced, overlap=overlap)\n",
    "\n",
    "vdgen = DataSetGenerator(imgs=val_img_list, batch_size=batch_size, \n",
    "                         time_step=time_steps, imgw=img_w, imgh=img_h, \n",
    "                         seq_type=data_seq_type, label_type=data_label_type,\n",
    "                         stacked=stakced, overlap=overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, use_bn=True):\n",
    "        super(EncodeBlock, self).__init__()\n",
    "        self.use_bn = use_bn       \n",
    "        self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\")\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.lrelu= layers.LeakyReLU(0.2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        return self.lrelu(x)\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, blk_cnt=5):\n",
    "        super(Encoder, self).__init__()\n",
    "        filters = [64,128,256,512,512,512,512,512]\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = filters[i]\n",
    "            if i == 0:\n",
    "                self.blocks.append(EncodeBlock(f, use_bn=False))\n",
    "            else:\n",
    "                self.blocks.append(EncodeBlock(f))\n",
    "    \n",
    "    def call(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "    \n",
    "    def get_summary(self, input_shape=(None, img_w, img_h, 1)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeBlock(layers.Layer):\n",
    "    def __init__(self, f, dropout=True):\n",
    "        super(DecodeBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.Transconv = layers.Conv3DTranspose(filters=f,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\")\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.Transconv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        if self.dropout:\n",
    "            x = layers.Dropout(.5)(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "    \n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, blk_cnt=4):\n",
    "        super(Decoder, self).__init__()\n",
    "        filters = [512,512,512,512,256,128,64]\n",
    "        \n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = filters[i]\n",
    "            if i < 3:\n",
    "                self.blocks.append(DecodeBlock(f))\n",
    "            else:\n",
    "                self.blocks.append(DecodeBlock(f, dropout=False))\n",
    "                \n",
    "        self.blocks.append(layers.Conv3DTranspose(filters=1,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, 2, 2),\n",
    "                    padding=\"same\"))\n",
    "        \n",
    "    def call(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderGenerator(Model):\n",
    "    def __init__(self, blk_cnt=4):\n",
    "        super(EncoderDecoderGenerator, self).__init__()\n",
    "        self.encoder = Encoder(blk_cnt)\n",
    "        self.decoder = Decoder(blk_cnt-1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "   \n",
    "    def get_summary(self, input_shape=(None, img_w, img_h, 1)):\n",
    "        inputs = Input(input_shape)\n",
    "        return Model(inputs, self.call(inputs)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscBlock(layers.Layer):\n",
    "    def __init__(self, n_filters, stride=2, custom_pad=0, use_bn=True, act=True):\n",
    "        super(DiscBlock, self).__init__()\n",
    "        self.custom_pad = custom_pad\n",
    "        self.use_bn = use_bn\n",
    "        self.act = act\n",
    "        \n",
    "        # outputsize = (w - f + 2*p) / s + 1\n",
    "        if custom_pad > 0:\n",
    "            self.padding = layers.ZeroPadding3D(padding=(0,custom_pad,custom_pad))\n",
    "            self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, stride, stride),\n",
    "                    padding=\"valid\")\n",
    "        else:\n",
    "            self.conv = layers.Conv3D(filters=n_filters,\n",
    "                    kernel_size=(1, 4, 4),\n",
    "                    strides=(1, stride, stride),\n",
    "                    padding=\"same\")\n",
    "        \n",
    "        self.batchnorm = layers.BatchNormalization() if use_bn else None\n",
    "        self.lrelu = layers.LeakyReLU(0.2) if act else None\n",
    "        \n",
    "    def call(self, x):\n",
    "        if self.custom_pad:\n",
    "            x = self.padding(x)\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "                \n",
    "        if self.use_bn:\n",
    "            x = self.batchnorm(x)\n",
    "            \n",
    "        if self.act:\n",
    "            x = self.lrelu(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, blk_cnt=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.concat = layers.Concatenate()\n",
    "\n",
    "        filters = [64,128,256,512,512,512]\n",
    "        self.blocks = []\n",
    "        for i in range(blk_cnt):\n",
    "            f = filters[i]\n",
    "            self.blocks.append(DiscBlock(\n",
    "                n_filters=f,\n",
    "                stride=2,\n",
    "                custom_pad=0,\n",
    "                use_bn=False if i==0 else True,\n",
    "                act=True\n",
    "            ))\n",
    "\n",
    "        self.blocks.append(DiscBlock(n_filters=512, stride=1, custom_pad=1, use_bn=True, act=True))\n",
    "        self.blocks.append(DiscBlock(n_filters=1, stride=1, custom_pad=1, use_bn=False, act=False))\n",
    "        self.sigmoid = layers.Activation(\"sigmoid\")\n",
    "\n",
    "\n",
    "    def call(self, x, y):\n",
    "        out = self.concat([x, y])\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        return self.sigmoid(out)\n",
    "    \n",
    "    def get_summary(self, x_shape=(None, img_w, img_h, 1), y_shape=(None, img_w, img_h, 1)):\n",
    "        x, y = Input(x_shape), Input(y_shape) \n",
    "        return Model((x, y), self.call(x, y)).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    '''\n",
    "    모델학습 초기에 learning rate를 급격히 높였다가, \n",
    "    서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법\n",
    "    학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소\n",
    "    '''\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "mae = losses.MeanAbsoluteError()\n",
    "\n",
    "def get_gene_loss(fake_output, real_output, fake_disc):\n",
    "    l1_loss = mae(real_output, fake_output)\n",
    "    gene_loss = bce(tf.ones_like(fake_disc), fake_disc)\n",
    "    return gene_loss, l1_loss\n",
    "\n",
    "def get_disc_loss(fake_disc, real_disc):\n",
    "    return bce(tf.zeros_like(fake_disc), fake_disc) + bce(tf.ones_like(real_disc), real_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_learning_rate = CustomSchedule(d_model=64, warmup_steps=40)\n",
    "disc_learning_rate = CustomSchedule(d_model=64, warmup_steps=40)\n",
    "\n",
    "gene_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
    "disc_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = EncoderDecoderGenerator(blk_cnt=enc_blk_count)\n",
    "discriminator = Discriminator(blk_cnt=disc_blk_count)\n",
    "\n",
    "history = {'gen_loss':[], 'disc_loss':[], 'real_accuracy':[], 'fake_accuracy':[], 'l1_loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(sketch, label):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generator 예측\n",
    "        fake_label = generator(sketch, training=True)\n",
    "        # Discriminator 예측\n",
    "        fake_disc = discriminator(sketch, fake_label, training=True)\n",
    "        real_disc = discriminator(sketch, label, training=True)\n",
    "        # Generator 손실 계산\n",
    "        gene_loss, l1_loss = get_gene_loss(fake_label, label, fake_disc)\n",
    "        gene_total_loss = gene_loss + (100 * l1_loss) ## <===== L1 손실 반영 λ=100\n",
    "        # Discrminator 손실 계산\n",
    "        disc_loss = get_disc_loss(fake_disc, real_disc)\n",
    "                \n",
    "    gene_gradient = gene_tape.gradient(gene_total_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return gene_loss, l1_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 2\n",
    "\n",
    "it = iter(tdgen)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    x, y = next(it)\n",
    "    g_loss, l1_loss, d_loss = train_step(x, y)\n",
    "\n",
    "    history['gen_loss'].append(g_loss)\n",
    "    history['disc_loss'].append(d_loss)\n",
    "    history['l1_loss'].append(l1_loss)\n",
    "\n",
    "    print(f\"{epoch}  Gloss:{g_loss.numpy():.4f}  L1:{l1_loss.numpy():.4f}  Dloss:{d_loss.numpy():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # summarize history for loss  \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history['gen_loss'])  \n",
    "    plt.plot(history['disc_loss'])  \n",
    "    plt.plot(history['l1_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('batch iters')  \n",
    "    plt.legend(['gen_loss', 'disc_loss', 'l1_loss'], loc='upper left')  \n",
    "\n",
    "    # summarize history for accuracy  \n",
    "    # plt.subplot(212)  \n",
    "    # plt.plot(history['fake_accuracy'])  \n",
    "    # plt.plot(history['real_accuracy'])  \n",
    "    # plt.title('discriminator accuracy')  \n",
    "    # plt.ylabel('accuracy')  \n",
    "    # plt.xlabel('batch iters')  \n",
    "    # plt.legend(['fake_accuracy', 'real_accuracy'], loc='upper left')  \n",
    "    \n",
    "    # training_history 디렉토리에 epoch별로 그래프를 이미지 파일로 저장합니다.\n",
    "    # plt.savefig(os.path.join(history_path, 'train_history_{:04d}.png'.format(epoch)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arry5d_to_img(arry5d, save_as='', threshold=0.0):\n",
    "    frmimg_cnt = arry5d.shape[1]\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = frmimg_cnt, figsize=(15, 3))\n",
    "\n",
    "    for idx, num in enumerate(range(0, frmimg_cnt)):\n",
    "        frm = ImgFrame(img=arry5d[0][idx][:, :, :], do_norm=False)\n",
    "        if threshold > 0.0:\n",
    "            frm.threshold(threshold=threshold)\n",
    "        img = frm.to_image()\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset중 하나만 뽑아서 예측에 입력\n",
    "it = iter(vdgen)\n",
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 이미지 한개 표시\n",
    "arry5d_to_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 이미지 한개 표시.\n",
    "arry5d_to_img(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 예측하여 이미지 표시.\n",
    "in_x = x[:1, :, :, :, :]\n",
    "pred = generator(in_x)\n",
    "\n",
    "file_name = os.path.join(cfg.TEMP_DATA_PATH, 'result.gif')\n",
    "arry5d_to_img(pred, save_as=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user가 그린 임의의 그림 예측.\n",
    "# user_file_name = os.path.join(cfg.TEMP_DATA_PATH, 'user_draw.gif')\n",
    "# user_draw = VideoClip(gif_path=user_file_name)\n",
    "# user_draw.resize(img_w, img_h, inplace=True)\n",
    "# arry5d = user_draw.to_array(expand=True)\n",
    "# print(arry5d.shape)\n",
    "# arry5d_to_img(arry5d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = generator(arry5d)\n",
    "\n",
    "# file_name = os.path.join(cfg.TEMP_DATA_PATH, 'result.gif')\n",
    "# arry5d_to_img(pred, save_as=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6debceb626036820d184549e25d059a55b6b8771e25bc8133db281d329c34fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
